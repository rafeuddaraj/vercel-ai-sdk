Now that we have our project set up, let's build our first AI feature, generating text responses from AI. We'll tackle this in two parts. First, we'll create a route handler to communicate with OpenAI. Second, we'll create a UI to display the response. Let's start by creating a route handler. In the app folder, create a new folder and call it API. This is where all our API routes will live. Now inside the API folder create another folder called completion. This name will become part of our API

endpoint. Finally inside completion create a new file called route.ts. This is where we will write our handler code. Start by defining an async post request handler. Export async function post. The function name must be post as this tells which HTTP method this handler responds to. Next, let's add our imports at the top of the file. import the generate text function from the core AI package and the OpenAI provider from AI SDK/OPAI package. These work together to generate text using OpenAI's models. Inside the

post function, let's make our first AI call. We'll call generate text with an object containing two properties. The first property is model. This specifies which language model to use. We'll use the GPT 4.1 nano from OpenAI. So call openAI passing in GPT-4.1- nano. We will explore different models later on but for now know that GPD 4.1 nano is a fast efficient model perfect for generating text. Now the second property is prompt. This is the instruction we give to the model. For now let's hardcode explain what an LLM

is in simple terms. The generate text function returns a promise that resolves to an object containing the generated text. Let's await the result and dstructure the text property from the resulting object. Finally, let's return it as JSON. Return response.json object with key and value set to text. We have just created our first AI power API route. Time to test it. We'll use ThunderClient, a VS Code extension for testing APIs. Click on the extension new request. Change the method to post and

send a request to HTTP localhost 3000/ AI/CM completion. The request should take a few seconds and then you'll see the response from the AI. It's an object with a property text and the value is the text generated from AI. This answer is in response to our prompt. Explain what an LLM is in simple terms. So sure, an LLM or large language model is kind of a computer program and you can read the rest. But it is quite clear a route handler is working as expected. 11 lines of code to interact with AI. How crazy is that? But

now that we have our API, let's implement the UI. A UI will accept user input and display the AI's response. So, go back to the app folder and create a new folder called UI. Inside UI, create another folder called completion. And in here, create a new file called page.tsx. Now, this folder structure is not an XJS convention. I just like organizing the UI folders to match our API structure. It makes the project easier to navigate. The file names however are not flexible. You have to call it page.tsx and

route.ts. All right, let's build our UI component step by step. Start by creating the basic component structure. So export default function completion page. At the top, we'll add the use client directive as this will be a client component that will make use of react state and handle interactivity. For the JSX, we'll start with a container div element. And within the container, we'll add a placeholder for our completion text. So, display area for completion will go here. At the bottom of the container

goes the form. Within the form, we'll add another div container with an input and a send button. For the input, we'll add a placeholder. How can I help you? For button, type is equal to submit. Now that we have the structure, we can use Tailwind classes to style all the elements. And I'll skip this part in the video as styling components is not the focus of the course. You can see I've added Tailwind classes to all the elements. And you can copy these styles from the GitHub repo, but also feel free

to style the UI to your liking. You can see this page in the browser by navigating to localhost 3000 /comp completion. You can see at the bottom of the screen, we have an input, how can I help you with a send button and space for the completion text. Now, let's go back to our editor and make the input interactive by adding state at the top. import use state from React and create a state variable to track the input value. We'll call it prompt. The setter function set prompt and the initial

value is an empty string. This is for the user input. On the input element, we can bind value to prompt and on change we can call set prompt passing in event.target dot value. Perfect. Now our input is controlled by React state. Next, let's add the functionality to call our API route handler. We'll need more state variables and a submit handler. We'll create a variable called completion. The set a function set completion and the initial value is an empty string. This is for the AI response. We'll also

create loading set is loading with an initial value of false. This is our loading flag. Next, we define our submit handler. So, const complete is the name of our function and this is an async function. The function receives an event of type form event and we begin by preventing the default behavior of form submission and reloading the page. Next, we call set loading and pass in true. We'll also clear the input immediately for better UX. Next, we'll add a try block where we make our fetch request.

So, const response is equal to await fetch and the endpoint is / API/comp completion. We also provide the options object method is post headers content type application/json and body JSON dotst stringify and we pass in the prompt. Once we get back the response we convert it to JSON. So await response.json JSON we store it in data and then we'll call set completion passing in data.ext we'll add a finally block and set ease loading to false. Now let's connect this handler to our form and display the

results. So form on submit is equal to complete which is the function we've just defined and then based on the loading flag we will display the AI response. So if e is loading is true we'll render a div tag with the text loading. Very simple. If e loading is false we check if the AI completion exists. If it does, we render a div tag with the completion has content. And if the completion doesn't exist yet, we simply render null. We will also disable the send button when ease is loading is

true. Finally, let's add proper error handling. We'll add a state variable to track errors and display them if they occur. So use state. We'll call this error. the setter function as set error and initially the value will be null. The type is going to be either string or null as we will populate the state variable with the error message when it occurs. So in the try block if not response do okay throw a new error data. Or something went wrong. data. error will point to the error thrown from our

API route and if it doesn't exist we fall back to something went wrong and after the try block we will add catch we handle the error we console log the error and then we set the error if error is instance of error we set error dot message otherwise something went wrong please try again this right here is necessary to satisfy TypeScript. Now that we have an error variable and we are able to throw errors, let's update the JSX to show the errors within the div container. If there is an error, we

render that error and we apply some TIN classes. Perfect. We've built our UI component progressively. We started with the basics JSX structure, added state to make the input interactive, implemented the API call functionality, and added proper error handling. This approach lets you see the component working at each stage and makes it easier to understand how the pieces fit together. Now, I strongly encourage you to type this code yourself. It really helps with learning. But if you need the completed

code, check out the GitHub repo linked in the description. And now that we have our UI ready, we need to modify our route handler to accept the prompt from the request body. Instead of using a hard-coded prompt, we will also add error handling. So go back to route.ts and update the post handler function. We'll update the handler to accept a request parameter. So request of type request. From the request body, extract the user prompt. So await request.json. JSON. This returns a promise that resolves to the request body parsed as

JSON. We will dstructure the prompt property. So, const prompt and pass it directly to generate text. So, prompt is the key and prompt is the value and you can rely on ESX shorthand syntax and specify just prompt. We'll then wrap this in a try catch block to handle any errors. So try catch and if there is an error console dot error error generating text and we log the error and we return response.json error failed to generate text. We also specify status 500. We can change console log to console

error in page.tpsx as well. All right, that was a lot of code but now it's time to see it in action. Make sure your dev server is running. Navigate to / UI/comp completion and try asking explain machine learning in one paragraph. Press enter. You should see the loading state. Then the AI response appears. Modify the model name to force an error. So nano1 23. Send a new request. Hello. And you should see the error message failed to generate text. There you go. We've built our very first AI powered feature text

completion. Let me revert the model name and quickly summarize what we have done. First, we created a route handler to communicate with OpenAI's API. We made use of generate text from AI core package and OpenAI from AI SDK/OPAI. For the UI, we created a clean form input and response display. We set up state variables. We accepted the prompt, made a fetch request passing in the prompt and set the completion text. Based on the state variables, we display either the error, the loading text or the completion. Text completion like

this is perfect for Q&A features, content summarization, or any scenario where you need AI generated text. Just remember, each API call costs money. So start with simple prompts while learning and keep an eye on your OpenAI usage dashboard. All right, our text completion works great. Next, we'll learn how to improve this experience with streaming responses.

